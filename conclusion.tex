\section{Conclusions}
\vspace{-2mm}
%Discuss which recipes worked and why. Discuss the importance of semantic representation, scaling features and multi-modality.
In this paper, we attempt to capture the underlying structure of human communication by jointly considering visual and language cues. We claim and experimentally validate that given a large-video collection having subtitles, it is possible to discover activity steps without any supervision over activities or object categories. Experimental evaluation also suggests the available noisy and incomplete multi-modal information is powerful enough to not only discover activity steps but also describe them with natural language.
\vspace{-2mm}
