\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}}
\citation{vidAbstraction}
\citation{beyondSearch}
\citation{createSum}
\citation{lee2012discovering}
\citation{lu2013story}
\citation{rui2000automatically}
\citation{storyGraph}
\citation{khosla2013large}
\citation{kim2014joint}
\citation{potapov2014category}
\citation{matching}
\citation{connecting}
\citation{zitnick2013learning}
\citation{zitnick2013bringing}
\citation{kong2014you}
\citation{fidler2013sentence}
\citation{yu2013grounded}
\citation{motwani2012improving}
\citation{ordonez2011im2text}
\citation{kiros2014multimodal}
\citation{socher2014grounded}
\citation{farhadi2010every}
\citation{farhadi2010every}
\citation{socher2014grounded}
\citation{kiros2014multimodal}
\citation{deepAlignment}
\citation{cookingSemantics}
\citation{logicRecipe}
\citation{logicRecipe}
\citation{flowGraph}
\citation{beetz}
\citation{cookie}
\citation{alignment}
\citation{photoshop}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Related Work}{2}{section.2}}
\@writefile{toc}{\contentsline {paragraph}{Video Summarization}{2}{section*.1}}
\@writefile{brf}{\backcite{vidAbstraction}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{beyondSearch}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{createSum}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{lee2012discovering, lu2013story}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{rui2000automatically}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{storyGraph}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{khosla2013large}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{kim2014joint}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{potapov2014category}{{2}{2}{section*.1}}}
\@writefile{toc}{\contentsline {paragraph}{Understanding Multi-Modal Information:}{2}{section*.2}}
\@writefile{brf}{\backcite{matching}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{connecting}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{zitnick2013learning,zitnick2013bringing}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{kong2014you}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{fidler2013sentence}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{yu2013grounded}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{motwani2012improving}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{ordonez2011im2text}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{kiros2014multimodal,socher2014grounded,farhadi2010every}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{farhadi2010every}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{socher2014grounded,kiros2014multimodal,deepAlignment}{{2}{2}{section*.2}}}
\@writefile{toc}{\contentsline {paragraph}{Activity Detection/Recognition:}{2}{section*.3}}
\@writefile{toc}{\contentsline {paragraph}{Recipe Understanding}{2}{section*.4}}
\@writefile{brf}{\backcite{cookingSemantics,logicRecipe}{{2}{2}{section*.4}}}
\@writefile{brf}{\backcite{logicRecipe}{{2}{2}{section*.4}}}
\@writefile{brf}{\backcite{flowGraph}{{2}{2}{section*.4}}}
\@writefile{brf}{\backcite{beetz,cookie}{{2}{2}{section*.4}}}
\@writefile{brf}{\backcite{alignment}{{2}{2}{section*.4}}}
\@writefile{brf}{\backcite{photoshop}{{2}{2}{section*.4}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Method}{2}{section.3}}
\newlabel{sec:overview}{{3}{2}{\hskip -1em.~Method}{section.3}{}}
\citation{scgp}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Components of our recipe understanding method. \textbf  {Query:} We query the YouTube for top 100 \emph  {How To} videos and filter the outliers; \textbf  {Framewise Representation:} We automatically extract object clusters and salient word in order to find multi-modal representation of each frame. \textbf  {Unsupervised Activity Detection:} We jointly cluster videos in order to learn activities/steps related to the recipe.\relax }}{3}{figure.caption.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:overview}{{1}{3}{Components of our recipe understanding method. \textbf {Query:} We query the YouTube for top 100 \emph {How To} videos and filter the outliers; \textbf {Framewise Representation:} We automatically extract object clusters and salient word in order to find multi-modal representation of each frame. \textbf {Unsupervised Activity Detection:} We jointly cluster videos in order to learn activities/steps related to the recipe.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Video Collection and Outlier Detection}{3}{subsection.3.1}}
\newlabel{filter}{{3.1}{3}{\hskip -1em.~Video Collection and Outlier Detection}{subsection.3.1}{}}
\citation{cpmc}
\citation{keysegments}
\citation{scgp}
\citation{scgp}
\citation{scgp_eigen}
\@writefile{brf}{\backcite{scgp}{{4}{3.1}{subsection.3.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Sample videos which our algorithm discards as an outlier for the query \emph  {How to make a milkshake?}.} These videos are about a toy milkshake, a milkshake charm and a funny video about How to NOT make milkshakes.\relax }}{4}{figure.caption.6}}
\newlabel{outliers}{{2}{4}{\textbf {Sample videos which our algorithm discards as an outlier for the query \emph {How to make a milkshake?}.} These videos are about a toy milkshake, a milkshake charm and a funny video about How to NOT make milkshakes.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Semantic Multi-Modal Frame Representation}{4}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Learning Language Atoms}{4}{subsubsection.3.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Learning Visual Atoms}{4}{subsubsection.3.2.2}}
\@writefile{brf}{\backcite{cpmc}{{4}{3.2.2}{subsubsection.3.2.2}}}
\@writefile{brf}{\backcite{keysegments}{{4}{3.2.2}{subsubsection.3.2.2}}}
\@writefile{toc}{\contentsline {paragraph}{Joint Region Proposal Clustering:}{4}{section*.7}}
\@writefile{brf}{\backcite{scgp}{{4}{3.2.2}{figure.caption.8}}}
\citation{scgp}
\citation{scgp_eigen}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Visualization of the joint proposal clustering.} Here, we show the 1NN video graph and 2NN region graph. Each region proposal is linked to its 2 nearest neighbours from the video it belongs and 2 nearest neighbours from the videos it is neighbour of.\relax }}{5}{figure.caption.8}}
\newlabel{hierProposal}{{3}{5}{\textbf {Visualization of the joint proposal clustering.} Here, we show the 1NN video graph and 2NN region graph. Each region proposal is linked to its 2 nearest neighbours from the video it belongs and 2 nearest neighbours from the videos it is neighbour of.\relax }{figure.caption.8}{}}
\@writefile{brf}{\backcite{scgp,scgp_eigen}{{5}{3.2.2}{equation.3.1}}}
\@writefile{brf}{\backcite{scgp,scgp_eigen}{{5}{3.2.2}{equation.3.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Randomly selected images of randomly selected clusters learned for \emph  {How to hard boil an egg?}\relax }}{5}{figure.caption.9}}
\newlabel{cvis}{{4}{5}{Randomly selected images of randomly selected clusters learned for \emph {How to hard boil an egg?}\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Multi-Modal Representation of Frames}{5}{subsubsection.3.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.\nobreakspace  {}Unsupervised Activity Representation}{5}{subsection.3.3}}
\newlabel{basics}{{3.3}{5}{\hskip -1em.~Unsupervised Activity Representation}{subsection.3.3}{}}
\citation{foxBPHMM}
\citation{ibp}
\citation{ibp}
\citation{foxBPHMM}
\citation{foxBPHMM}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Visualization of the representation of a sample frame.} 3 of the region proposals of the frame is included in the object clusters and 3 of the words in the subtitle of the frame is included in the salient word list.\relax }}{6}{figure.caption.10}}
\newlabel{visFrame}{{5}{6}{\textbf {Visualization of the representation of a sample frame.} 3 of the region proposals of the frame is included in the object clusters and 3 of the words in the subtitle of the frame is included in the salient word list.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Beta Process Hidden Markov Model}{6}{subsubsection.3.3.1}}
\@writefile{brf}{\backcite{foxBPHMM}{{6}{3.3.1}{subsubsection.3.3.1}}}
\@writefile{brf}{\backcite{ibp}{{6}{3.3.1}{equation.3.4}}}
\@writefile{brf}{\backcite{ibp}{{6}{3.3.1}{equation.3.4}}}
\@writefile{brf}{\backcite{foxBPHMM}{{6}{3.3.1}{equation.3.4}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Gibbs sampling for BP-HMM}{6}{subsubsection.3.3.2}}
\@writefile{brf}{\backcite{foxBPHMM}{{6}{3.3.2}{subsubsection.3.3.2}}}
\citation{wikiHow}
\citation{wikiHow}
\citation{languageModel}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Graphical model for BP-HMM:} The left plate represent the set of activities and right plate represent the set of videos. Each video choose a subset of activities through $\mathbf  {f^{(i)}}$ and transition probabilities between them. After the features are selected, the marginal model of the each video becomes an Hidden Markov Model. \emph  {See the text for the details.}\relax }}{7}{figure.caption.11}}
\newlabel{bphmmo}{{6}{7}{\textbf {Graphical model for BP-HMM:} The left plate represent the set of activities and right plate represent the set of videos. Each video choose a subset of activities through $\mathbf {f^{(i)}}$ and transition probabilities between them. After the features are selected, the marginal model of the each video becomes an Hidden Markov Model. \emph {See the text for the details.}\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Experiments}{7}{section.4}}
\@writefile{brf}{\backcite{wikiHow}{{7}{4}{section.4}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Dataset}{7}{subsection.4.1}}
\newlabel{dataset:sec}{{4.1}{7}{\hskip -1em.~Dataset}{subsection.4.1}{}}
\@writefile{brf}{\backcite{wikiHow}{{7}{4.1}{subsection.4.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Implementation Details}{7}{subsection.4.2}}
\newlabel{imp_det}{{4.2}{7}{\hskip -1em.~Implementation Details}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Parameters:}{7}{section*.12}}
\@writefile{toc}{\contentsline {paragraph}{Aligning Clusters:}{7}{section*.13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\hskip -1em.\nobreakspace  {}Qualitative Results}{7}{subsection.4.3}}
\@writefile{brf}{\backcite{languageModel}{{7}{4.3}{subsection.4.3}}}
\citation{rabiner}
\citation{acticityFeature}
\citation{potapov2014category}
\citation{potapov2014category}
\newlabel{recipe:ommelette}{{7a}{8}{How to make an omelet?\relax }{figure.caption.14}{}}
\newlabel{sub@recipe:ommelette}{{a}{8}{How to make an omelet?\relax }{figure.caption.14}{}}
\newlabel{recipe:milkshake}{{7b}{8}{How to make a milkshake?\relax }{figure.caption.14}{}}
\newlabel{sub@recipe:milkshake}{{b}{8}{How to make a milkshake?\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Temporal segmentation of the videos by our method and ground truth segmentation. We also color code the learned activity labels and visualize sample frames and the automatically generated captions for some of them. \emph  {Best viewed in color.}\relax }}{8}{figure.caption.14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}\hskip -1em.\nobreakspace  {}Quantitative Results}{8}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Baselines}{8}{subsubsection.4.4.1}}
\@writefile{brf}{\backcite{rabiner}{{8}{4.4.1}{subsubsection.4.4.1}}}
\@writefile{brf}{\backcite{acticityFeature}{{8}{4.4.1}{subsubsection.4.4.1}}}
\@writefile{brf}{\backcite{potapov2014category}{{8}{4.4.1}{subsubsection.4.4.1}}}
\@writefile{brf}{\backcite{potapov2014category}{{8}{4.4.1}{subsubsection.4.4.1}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Metrics}{8}{subsubsection.4.4.2}}
\bibstyle{ieee}
\bibdata{recipeUnderstanding}
\bibcite{wikiHow}{1}
\bibcite{matching}{2}
\bibcite{beetz}{3}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces $IOU_{max}$ stuff, not real numbers just a place holder\relax }}{9}{figure.caption.15}}
\newlabel{mIOU}{{8}{9}{$IOU_{max}$ stuff, not real numbers just a place holder\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces $AP_{max}$ stuff, not real numbers just a place holder\relax }}{9}{figure.caption.15}}
\newlabel{mmAP}{{9}{9}{$AP_{max}$ stuff, not real numbers just a place holder\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Results}{9}{subsubsection.4.4.3}}
\@writefile{toc}{\contentsline {paragraph}{Are the activities detected accurately?}{9}{section*.16}}
\@writefile{toc}{\contentsline {paragraph}{Are the same activities in different videos linked to each other?}{9}{section*.17}}
\@writefile{toc}{\contentsline {paragraph}{How important is each modality?}{9}{section*.18}}
\bibcite{cookie}{4}
\bibcite{cpmc}{5}
\bibcite{farhadi2010every}{6}
\bibcite{fidler2013sentence}{7}
\bibcite{foxBPHMM}{8}
\bibcite{photoshop}{9}
\bibcite{ibp}{10}
\bibcite{createSum}{11}
\bibcite{beyondSearch}{12}
\bibcite{deepAlignment}{13}
\bibcite{khosla2013large}{14}
\bibcite{kim2014joint}{15}
\bibcite{storyGraph}{16}
\bibcite{kiros2014multimodal}{17}
\bibcite{kong2014you}{18}
\bibcite{lee2012discovering}{19}
\bibcite{keysegments}{20}
\bibcite{lu2013story}{21}
\bibcite{alignment}{22}
\bibcite{cookingSemantics}{23}
\bibcite{flowGraph}{24}
\bibcite{motwani2012improving}{25}
\bibcite{scgp}{26}
\bibcite{ordonez2011im2text}{27}
\bibcite{scgp_eigen}{28}
\bibcite{potapov2014category}{29}
\bibcite{rabiner}{30}
\bibcite{rui2000automatically}{31}
\bibcite{connecting}{32}
\bibcite{socher2014grounded}{33}
\bibcite{logicRecipe}{34}
\bibcite{vidAbstraction}{35}
\bibcite{yu2013grounded}{36}
\bibcite{zitnick2013bringing}{37}
\bibcite{zitnick2013learning}{38}
