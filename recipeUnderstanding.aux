\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Given a large video collection (frames and subtitles) of an structured category (\emph  {e.g}\onedot  , How to cook an omelette?), we discover activity steps (\emph  {e.g}\onedot  , crack the eggs). We also parse the videos based on the discovered steps.\relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{teaser}{{1}{1}{Given a large video collection (frames and subtitles) of an structured category (\eg , How to cook an omelette?), we discover activity steps (\eg , crack the eggs). We also parse the videos based on the discovered steps.\relax \relax }{figure.caption.1}{}}
\citation{vidAbstraction}
\citation{lee2012discovering}
\citation{lu2013story}
\citation{rui2000automatically}
\citation{storyGraph}
\citation{gupta2009understanding}
\citation{khosla2013large}
\citation{kim2014joint}
\citation{potapov2014category}
\citation{matching}
\citation{connecting}
\citation{zitnick2013learning}
\citation{zitnick2013bringing}
\citation{kong2014you}
\citation{fidler2013sentence}
\citation{yu2013grounded}
\citation{motwani2012improving}
\citation{ordonez2011im2text}
\citation{kiros2014multimodal}
\citation{socher2014grounded}
\citation{farhadi2010every}
\citation{farhadi2010every}
\citation{socher2014grounded}
\citation{kiros2014multimodal}
\citation{deepAlignment}
\citation{kuehne2011hmdb}
\citation{UCF101}
\citation{niebles10_eccv}
\citation{laptev08_cvpr}
\citation{efros03_iccv}
\citation{ryoo09_iccv}
\citation{THUMOS14}
\citation{oneata2014lear}
\citation{jainuniversity}
\citation{duchenne09_iccv}
\citation{hoai11_cvpr}
\citation{laptev07_iccv}
\citation{bojanowski14_eccv}
\citation{pirsiavash14_cvpr}
\citation{niebles10_eccv}
\citation{yao10b_cvpr}
\citation{jain13_cvpr}
\citation{lan14_eccv}
\citation{lan14_vs}
\citation{sun2014discover}
\citation{das2013thousand}
\citation{barbu2012video}
\citation{cookingSemantics}
\citation{logicRecipe}
\citation{logicRecipe}
\citation{beetz}
\citation{cookie}
\citation{alignment}
\citation{photoshop}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Related Work}{2}{section.2}}
\@writefile{brf}{\backcite{vidAbstraction}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{lee2012discovering, lu2013story,rui2000automatically}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{storyGraph}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{gupta2009understanding}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{khosla2013large}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{kim2014joint,potapov2014category}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{matching}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{connecting}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{zitnick2013learning,zitnick2013bringing}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{kong2014you}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{fidler2013sentence}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{yu2013grounded}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{motwani2012improving}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{ordonez2011im2text}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{kiros2014multimodal,socher2014grounded,farhadi2010every}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{farhadi2010every}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{socher2014grounded,kiros2014multimodal,deepAlignment}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{kuehne2011hmdb, UCF101, niebles10_eccv, laptev08_cvpr, efros03_iccv, ryoo09_iccv}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{THUMOS14, oneata2014lear, jainuniversity}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{duchenne09_iccv, hoai11_cvpr, laptev07_iccv, bojanowski14_eccv, pirsiavash14_cvpr}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{niebles10_eccv, yao10b_cvpr, jain13_cvpr,lan14_eccv, lan14_vs}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{sun2014discover,das2013thousand,barbu2012video}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{cookingSemantics,logicRecipe}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{logicRecipe}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{beetz,cookie}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{alignment}{{2}{2}{section.2}}}
\citation{cpmc}
\citation{keysegments}
\@writefile{brf}{\backcite{photoshop}{{3}{2}{section.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Overview}{3}{section.3}}
\newlabel{sec:overview}{{3}{3}{\hskip -1em.~Overview\relax }{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Forming the Multi-Modal Representation}{3}{section.4}}
\newlabel{atoms}{{4}{3}{\hskip -1em.~Forming the Multi-Modal Representation\relax }{section.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces We learn language and visual atoms to represent multi-modal information. Language atoms are frequent words and visual atoms are the clusters of object proposals.\relax }}{3}{figure.caption.2}}
\newlabel{fig:overview}{{2}{3}{We learn language and visual atoms to represent multi-modal information. Language atoms are frequent words and visual atoms are the clusters of object proposals.\relax \relax }{figure.caption.2}{}}
\@writefile{brf}{\backcite{cpmc}{{3}{4}{figure.caption.2}}}
\@writefile{brf}{\backcite{keysegments}{{3}{4}{figure.caption.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Representation for a sample frame.} Three of the object proposals of sample frame are in the visual atoms and three of the words are in the language atoms.\relax }}{3}{figure.caption.3}}
\newlabel{visFrame}{{3}{3}{\textbf {Representation for a sample frame.} Three of the object proposals of sample frame are in the visual atoms and three of the words are in the language atoms.\relax \relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Joint Proposal Clustering over Videos}{3}{section.5}}
\newlabel{jointProp}{{5}{3}{\hskip -1em.~Joint Proposal Clustering over Videos\relax }{section.5}{}}
\citation{scgp}
\citation{scgp}
\citation{scgp_eigen}
\citation{alexnet}
\citation{scgp}
\citation{scgp_eigen}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Joint proposal clustering.} Each object proposal is linked to its two NNs from the video it belongs and two NNs from the videos it is neighbour of. Dashed and solid lines denote the intra-video and inter-video edges, respectively. Black nodes are the proposals selected as part of the cluster and the gray ones are not selected. Similarly, the black and gray edges denote selected and not-selected, respectively.\relax }}{4}{figure.caption.4}}
\newlabel{hierProposal}{{4}{4}{\textbf {Joint proposal clustering.} Each object proposal is linked to its two NNs from the video it belongs and two NNs from the videos it is neighbour of. Dashed and solid lines denote the intra-video and inter-video edges, respectively. Black nodes are the proposals selected as part of the cluster and the gray ones are not selected. Similarly, the black and gray edges denote selected and not-selected, respectively.\relax \relax }{figure.caption.4}{}}
\@writefile{brf}{\backcite{scgp}{{4}{5}{figure.caption.4}}}
\newlabel{nonvec}{{1}{4}{\hskip -1em.~Joint Proposal Clustering over Videos\relax }{equation.5.1}{}}
\@writefile{brf}{\backcite{scgp,scgp_eigen}{{4}{5}{equation.5.1}}}
\@writefile{brf}{\backcite{alexnet}{{4}{5}{equation.5.1}}}
\@writefile{brf}{\backcite{scgp,scgp_eigen}{{4}{5}{equation.5.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Randomly selected images of four randomly selected clusters learned for \emph  {How to hard boil an egg?}\relax }}{4}{figure.caption.5}}
\newlabel{cvis}{{5}{4}{Randomly selected images of four randomly selected clusters learned for \emph {How to hard boil an egg?}\relax \relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}\hskip -1em.\nobreakspace  {}Unsupervised Parsing}{4}{subsection.5.1}}
\newlabel{basics}{{5.1}{4}{\hskip -1em.~Unsupervised Parsing\relax }{subsection.5.1}{}}
\newlabel{learning}{{5.1}{4}{\hskip -1em.~Unsupervised Parsing\relax }{subsection.5.1}{}}
\citation{foxBPHMM}
\citation{foxBPHMM}
\citation{foxBPHMM}
\citation{ibp}
\citation{ibp}
\citation{foxBPHMM}
\citation{foxBPHMM}
\citation{supp}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Beta Process Hidden Markov Model}{5}{subsubsection.5.1.1}}
\newlabel{bphmm}{{5.1.1}{5}{Beta Process Hidden Markov Model\relax }{subsubsection.5.1.1}{}}
\@writefile{brf}{\backcite{foxBPHMM}{{5}{5.1.1}{subsubsection.5.1.1}}}
\@writefile{brf}{\backcite{foxBPHMM}{{5}{5.1.1}{subsubsection.5.1.1}}}
\@writefile{brf}{\backcite{foxBPHMM}{{5}{5.1.1}{subsubsection.5.1.1}}}
\@writefile{brf}{\backcite{ibp}{{5}{5.1.1}{equation.5.4}}}
\@writefile{brf}{\backcite{ibp}{{5}{5.1.1}{equation.5.4}}}
\@writefile{brf}{\backcite{foxBPHMM}{{5}{5.1.1}{equation.5.4}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Graphical model for BP-HMM:} The left plate represent the activity steps and the right plate represent the videos. (\emph  {i.e}\onedot  the left plate is for the activity step discovery and right plate is for parsing.) \emph  {See Section\nobreakspace  {}\ref  {bphmm} for details.}\relax }}{5}{figure.caption.6}}
\newlabel{bphmmo}{{6}{5}{\textbf {Graphical model for BP-HMM:} The left plate represent the activity steps and the right plate represent the videos. (\ie the left plate is for the activity step discovery and right plate is for parsing.) \emph {See Section~\ref {bphmm} for details.}\relax \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Gibbs sampling for BP-HMM}{5}{subsubsection.5.1.2}}
\citation{wikiHow}
\citation{scgp}
\citation{languageModel}
\citation{supp}
\citation{kantorov2014}
\citation{rabiner}
\citation{potapov2014category}
\citation{potapov2014category}
\citation{THUMOS14}
\citation{liao05}
\@writefile{brf}{\backcite{foxBPHMM}{{6}{5.1.2}{subsubsection.5.1.2}}}
\@writefile{brf}{\backcite{supp}{{6}{5.1.2}{subsubsection.5.1.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.\nobreakspace  {}Experiments}{6}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}\hskip -1em.\nobreakspace  {}Dataset}{6}{subsection.6.1}}
\newlabel{dataset:sec}{{6.1}{6}{\hskip -1em.~Dataset\relax }{subsection.6.1}{}}
\@writefile{brf}{\backcite{wikiHow}{{6}{6.1}{subsection.6.1}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Outlier Detection}{6}{subsubsection.6.1.1}}
\newlabel{filter}{{6.1.1}{6}{Outlier Detection\relax }{subsubsection.6.1.1}{}}
\@writefile{brf}{\backcite{scgp}{{6}{6.1.1}{subsubsection.6.1.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Sample videos which our algorithm discards as an outlier for various queries.} A toy milkshake, a milkshake charm, a funny video about How to NOT make smoothie, a video about the danger of a fire, a cartoon video, a neck-tie video erroneously labeled as bow-tie, a song, and a lamb cooking mislabeled as chicken.\relax }}{6}{figure.caption.7}}
\newlabel{outliers}{{7}{6}{\textbf {Sample videos which our algorithm discards as an outlier for various queries.} A toy milkshake, a milkshake charm, a funny video about How to NOT make smoothie, a video about the danger of a fire, a cartoon video, a neck-tie video erroneously labeled as bow-tie, a song, and a lamb cooking mislabeled as chicken.\relax \relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}\hskip -1em.\nobreakspace  {}Qualitative Results}{6}{subsection.6.2}}
\@writefile{brf}{\backcite{languageModel}{{6}{6.2}{subsection.6.2}}}
\@writefile{brf}{\backcite{supp}{{6}{6.2}{subsection.6.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}\hskip -1em.\nobreakspace  {}Quantitative Results}{6}{subsection.6.3}}
\@writefile{brf}{\backcite{kantorov2014}{{6}{6.3}{subsection.6.3}}}
\@writefile{brf}{\backcite{rabiner}{{6}{6.3}{subsection.6.3}}}
\@writefile{brf}{\backcite{potapov2014category}{{6}{6.3}{subsection.6.3}}}
\@writefile{brf}{\backcite{potapov2014category}{{6}{6.3}{subsection.6.3}}}
\newlabel{recipe:ommelette}{{8a}{7}{How to make an omelet?\relax \relax }{figure.caption.8}{}}
\newlabel{sub@recipe:ommelette}{{a}{7}{How to make an omelet?\relax \relax }{figure.caption.8}{}}
\newlabel{recipe:milkshake}{{8b}{7}{How to make a milkshake?\relax \relax }{figure.caption.8}{}}
\newlabel{sub@recipe:milkshake}{{b}{7}{How to make a milkshake?\relax \relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Temporal segmentation of the videos and ground truth segmentation. We also color code the activity steps we discovered and visualize their key-frames and the automatically generated captions. \emph  {Best viewed in color.}\relax }}{7}{figure.caption.8}}
\newlabel{recipe:overall}{{8}{7}{Temporal segmentation of the videos and ground truth segmentation. We also color code the activity steps we discovered and visualize their key-frames and the automatically generated captions. \emph {Best viewed in color.}\relax \relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces $IOU_{cms}$ values for all categories, for all competing algorithms.\relax }}{7}{figure.caption.9}}
\newlabel{mIOU}{{9}{7}{$IOU_{cms}$ values for all categories, for all competing algorithms.\relax \relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces $AP_{cms}$ values for all categories, for all competing algorithms.\relax }}{7}{figure.caption.9}}
\newlabel{mmAP}{{10}{7}{$AP_{cms}$ values for all categories, for all competing algorithms.\relax \relax }{figure.caption.9}{}}
\@writefile{brf}{\backcite{THUMOS14}{{7}{6.3}{figure.caption.9}}}
\@writefile{brf}{\backcite{liao05}{{7}{6.3}{figure.caption.9}}}
\citation{potapov2014category}
\citation{potapov2014category}
\citation{robobrain}
\bibstyle{ieee}
\bibdata{recipeUnderstanding}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Qualitative results for parsing `Travel San Francisco' category.\relax }}{8}{figure.caption.10}}
\newlabel{sf}{{11}{8}{Qualitative results for parsing `Travel San Francisco' category.\relax \relax }{figure.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Average $IOU_{cms}$ and $mAP_{cms}$ over all categories.\relax }}{8}{table.caption.11}}
\@writefile{brf}{\backcite{potapov2014category}{{8}{1}{table.caption.11}}}
\@writefile{brf}{\backcite{potapov2014category}{{8}{1}{table.caption.11}}}
\newlabel{averM}{{1}{8}{Average $IOU_{cms}$ and $mAP_{cms}$ over all categories.\relax \relax }{table.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Semantic mean-average-precision $mAP_{sem}$.\relax }}{8}{table.caption.12}}
\@writefile{toc}{\contentsline {section}{\numberline {7}\hskip -1em.\nobreakspace  {}Conclusions}{8}{section.7}}
\@writefile{brf}{\backcite{robobrain}{{8}{7}{section.7}}}
\@writefile{toc}{\contentsline {section}{\numberline {8}\hskip -1em.\nobreakspace  {}Acknowledgements}{8}{section.8}}
\bibcite{supp}{1}
\bibcite{wikiHow}{2}
\bibcite{barbu2012video}{3}
\bibcite{matching}{4}
\bibcite{beetz}{5}
\bibcite{bojanowski14_eccv}{6}
\bibcite{cookie}{7}
\bibcite{cpmc}{8}
\bibcite{das2013thousand}{9}
\bibcite{duchenne09_iccv}{10}
\bibcite{efros03_iccv}{11}
\bibcite{farhadi2010every}{12}
\bibcite{fidler2013sentence}{13}
\bibcite{foxBPHMM}{14}
\bibcite{photoshop}{15}
\bibcite{ibp}{16}
\bibcite{gupta2009understanding}{17}
\bibcite{hoai11_cvpr}{18}
\bibcite{jain13_cvpr}{19}
\bibcite{jainuniversity}{20}
\bibcite{THUMOS14}{21}
\bibcite{kantorov2014}{22}
\bibcite{deepAlignment}{23}
\bibcite{khosla2013large}{24}
\bibcite{kim2014joint}{25}
\bibcite{storyGraph}{26}
\bibcite{kiros2014multimodal}{27}
\bibcite{kong2014you}{28}
\bibcite{alexnet}{29}
\bibcite{kuehne2011hmdb}{30}
\bibcite{lan14_vs}{31}
\bibcite{lan14_eccv}{32}
\bibcite{laptev08_cvpr}{33}
\bibcite{laptev07_iccv}{34}
\bibcite{lee2012discovering}{35}
\bibcite{keysegments}{36}
\bibcite{liao05}{37}
\bibcite{lu2013story}{38}
\bibcite{alignment}{39}
\bibcite{cookingSemantics}{40}
\bibcite{motwani2012improving}{41}
\bibcite{niebles10_eccv}{42}
\bibcite{scgp}{43}
\bibcite{oneata2014lear}{44}
\bibcite{ordonez2011im2text}{45}
\bibcite{scgp_eigen}{46}
\bibcite{pirsiavash14_cvpr}{47}
\bibcite{potapov2014category}{48}
\bibcite{rabiner}{49}
\bibcite{rui2000automatically}{50}
\bibcite{ryoo09_iccv}{51}
\bibcite{robobrain}{52}
\bibcite{languageModel}{53}
\bibcite{connecting}{54}
\bibcite{socher2014grounded}{55}
\bibcite{UCF101}{56}
\bibcite{sun2014discover}{57}
\bibcite{logicRecipe}{58}
\bibcite{vidAbstraction}{59}
\bibcite{yao10b_cvpr}{60}
\bibcite{yu2013grounded}{61}
\bibcite{zitnick2013bringing}{62}
\bibcite{zitnick2013learning}{63}
