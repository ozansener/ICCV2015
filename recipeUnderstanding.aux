\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}}
\citation{vidAbstraction}
\citation{beyondSearch}
\citation{createSum}
\citation{lee2012discovering}
\citation{lu2013story}
\citation{rui2000automatically}
\citation{storyGraph}
\citation{gupta2009understanding}
\citation{khosla2013large}
\citation{kim2014joint}
\citation{potapov2014category}
\citation{matching}
\citation{connecting}
\citation{zitnick2013learning}
\citation{zitnick2013bringing}
\citation{kong2014you}
\citation{fidler2013sentence}
\citation{yu2013grounded}
\citation{motwani2012improving}
\citation{ordonez2011im2text}
\citation{kiros2014multimodal}
\citation{socher2014grounded}
\citation{farhadi2010every}
\citation{farhadi2010every}
\citation{socher2014grounded}
\citation{kiros2014multimodal}
\citation{deepAlignment}
\citation{kuehne2011hmdb}
\citation{UCF101}
\citation{niebles10_eccv}
\citation{laptev08_cvpr}
\citation{efros03_iccv}
\citation{ryoo09_iccv}
\citation{THUMOS14}
\citation{oneata2014lear}
\citation{jainuniversity}
\citation{duchenne09_iccv}
\citation{hoai11_cvpr}
\citation{laptev07_iccv}
\citation{bojanowski14_eccv}
\citation{pirsiavash14_cvpr}
\citation{niebles10_eccv}
\citation{yao10b_cvpr}
\citation{jain13_cvpr}
\citation{lan14_eccv}
\citation{lan14_vs}
\citation{sun2014discover}
\citation{das2013thousand}
\citation{barbu2012video}
\citation{cookingSemantics}
\citation{logicRecipe}
\citation{logicRecipe}
\citation{flowGraph}
\citation{beetz}
\citation{cookie}
\citation{alignment}
\citation{photoshop}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Related Work}{2}{section.2}}
\@writefile{toc}{\contentsline {paragraph}{Video Summarization:}{2}{section*.1}}
\@writefile{brf}{\backcite{vidAbstraction}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{beyondSearch}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{createSum}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{lee2012discovering, lu2013story}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{rui2000automatically}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{storyGraph}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{gupta2009understanding}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{khosla2013large}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{kim2014joint}{{2}{2}{section*.1}}}
\@writefile{brf}{\backcite{potapov2014category}{{2}{2}{section*.1}}}
\@writefile{toc}{\contentsline {paragraph}{Modeling Visual and Language Information:}{2}{section*.2}}
\@writefile{brf}{\backcite{matching}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{connecting}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{zitnick2013learning,zitnick2013bringing}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{kong2014you}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{fidler2013sentence}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{yu2013grounded}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{motwani2012improving}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{ordonez2011im2text}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{kiros2014multimodal,socher2014grounded,farhadi2010every}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{farhadi2010every}{{2}{2}{section*.2}}}
\@writefile{brf}{\backcite{socher2014grounded,kiros2014multimodal,deepAlignment}{{2}{2}{section*.2}}}
\@writefile{toc}{\contentsline {paragraph}{Activity/Event Recognition:}{2}{section*.3}}
\@writefile{brf}{\backcite{kuehne2011hmdb, UCF101, niebles10_eccv, laptev08_cvpr, efros03_iccv, ryoo09_iccv}{{2}{2}{section*.3}}}
\@writefile{brf}{\backcite{THUMOS14, oneata2014lear, jainuniversity}{{2}{2}{section*.3}}}
\@writefile{brf}{\backcite{duchenne09_iccv, hoai11_cvpr, laptev07_iccv, bojanowski14_eccv, pirsiavash14_cvpr}{{2}{2}{section*.3}}}
\@writefile{brf}{\backcite{niebles10_eccv, yao10b_cvpr, jain13_cvpr,lan14_eccv, lan14_vs}{{2}{2}{section*.3}}}
\@writefile{brf}{\backcite{sun2014discover,das2013thousand,barbu2012video}{{2}{2}{section*.3}}}
\citation{scgp}
\@writefile{toc}{\contentsline {paragraph}{Recipe Understanding:}{3}{section*.4}}
\@writefile{brf}{\backcite{cookingSemantics,logicRecipe}{{3}{2}{section*.4}}}
\@writefile{brf}{\backcite{logicRecipe}{{3}{2}{section*.4}}}
\@writefile{brf}{\backcite{flowGraph}{{3}{2}{section*.4}}}
\@writefile{brf}{\backcite{beetz,cookie}{{3}{2}{section*.4}}}
\@writefile{brf}{\backcite{alignment}{{3}{2}{section*.4}}}
\@writefile{brf}{\backcite{photoshop}{{3}{2}{section*.4}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Overview}{3}{section.3}}
\newlabel{sec:overview}{{3}{3}{\hskip -1em.~Overview}{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Components of our recipe understanding method. \textbf  {Query:} We query the YouTube for top 100 \emph  {How To} videos and filter the outliers; \textbf  {Framewise Representation:} We automatically extract object clusters and salient word in order to find multi-modal representation of each frame. \textbf  {Unsupervised Activity Detection:} We jointly cluster videos in order to learn activities/steps related to the recipe.\relax }}{3}{figure.caption.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:overview}{{1}{3}{Components of our recipe understanding method. \textbf {Query:} We query the YouTube for top 100 \emph {How To} videos and filter the outliers; \textbf {Framewise Representation:} We automatically extract object clusters and salient word in order to find multi-modal representation of each frame. \textbf {Unsupervised Activity Detection:} We jointly cluster videos in order to learn activities/steps related to the recipe.\relax }{figure.caption.5}{}}
\citation{cpmc}
\citation{keysegments}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Video Collection and Outlier Detection}{4}{subsection.3.1}}
\newlabel{filter}{{3.1}{4}{\hskip -1em.~Video Collection and Outlier Detection}{subsection.3.1}{}}
\@writefile{brf}{\backcite{scgp}{{4}{3.1}{subsection.3.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Sample videos which our algorithm discards as an outlier for various queries.} First row include a video about a toy milkshake, a milkshake charm and a funny video about How to NOT make smoothie. Second row is a frozen yogurt recipe errornously labeled as \emph  {how to make a yougurt?}, an informative video about the danger of a fire while cooking and a cartoon about pancake. The final row is a neck-tie video errornously labeled as bow-tie, a song including the phrase \emph  {How to tell if a gold is real?} and a lamb cooking video mislabeled as \emph  {How to bake chicken?}\relax }}{4}{figure.caption.6}}
\newlabel{outliers}{{2}{4}{\textbf {Sample videos which our algorithm discards as an outlier for various queries.} First row include a video about a toy milkshake, a milkshake charm and a funny video about How to NOT make smoothie. Second row is a frozen yogurt recipe errornously labeled as \emph {how to make a yougurt?}, an informative video about the danger of a fire while cooking and a cartoon about pancake. The final row is a neck-tie video errornously labeled as bow-tie, a song including the phrase \emph {How to tell if a gold is real?} and a lamb cooking video mislabeled as \emph {How to bake chicken?}\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Semantic Multi-Modal Frame Representation}{4}{subsection.3.2}}
\@writefile{toc}{\contentsline {paragraph}{Learning Visual Atoms}{4}{section*.7}}
\@writefile{brf}{\backcite{cpmc}{{4}{3.2}{section*.7}}}
\@writefile{brf}{\backcite{keysegments}{{4}{3.2}{section*.7}}}
\@writefile{toc}{\contentsline {paragraph}{Learning Language Atoms}{4}{section*.8}}
\@writefile{toc}{\contentsline {paragraph}{Multi-Modal Representation of Frames}{4}{section*.9}}
\citation{scgp}
\citation{scgp}
\citation{scgp_eigen}
\citation{scgp}
\citation{scgp_eigen}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Visualization of the representation of a sample frame.} 3 of the region proposals of the frame is included in the object clusters and 3 of the words in the subtitle of the frame is included in the salient word list.\relax }}{5}{figure.caption.10}}
\newlabel{visFrame}{{3}{5}{\textbf {Visualization of the representation of a sample frame.} 3 of the region proposals of the frame is included in the object clusters and 3 of the words in the subtitle of the frame is included in the salient word list.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.\nobreakspace  {}Joint Region Proposal Clustering:}{5}{subsection.3.3}}
\newlabel{jointProp}{{3.3}{5}{\hskip -1em.~Joint Region Proposal Clustering:}{subsection.3.3}{}}
\@writefile{brf}{\backcite{scgp}{{5}{3.3}{figure.caption.11}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Visualization of the joint proposal clustering.} Here, we show the 1NN video graph and 2NN region graph. Each region proposal is linked to its 2 nearest neighbours from the video it belongs and 2 nearest neighbours from the videos it is neighbour of. THIS NEED WORK\relax }}{5}{figure.caption.11}}
\newlabel{hierProposal}{{4}{5}{\textbf {Visualization of the joint proposal clustering.} Here, we show the 1NN video graph and 2NN region graph. Each region proposal is linked to its 2 nearest neighbours from the video it belongs and 2 nearest neighbours from the videos it is neighbour of. THIS NEED WORK\relax }{figure.caption.11}{}}
\@writefile{brf}{\backcite{scgp,scgp_eigen}{{5}{3.3}{equation.3.1}}}
\citation{foxBPHMM}
\citation{ibp}
\citation{ibp}
\citation{foxBPHMM}
\@writefile{brf}{\backcite{scgp,scgp_eigen}{{6}{3.3}{equation.3.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Randomly selected images of randomly selected clusters learned for \emph  {How to hard boil an egg?}\relax }}{6}{figure.caption.12}}
\newlabel{cvis}{{5}{6}{Randomly selected images of randomly selected clusters learned for \emph {How to hard boil an egg?}\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}\hskip -1em.\nobreakspace  {}Unsupervised Activity Representation}{6}{subsection.3.4}}
\newlabel{basics}{{3.4}{6}{\hskip -1em.~Unsupervised Activity Representation}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Beta Process Hidden Markov Model}{6}{subsubsection.3.4.1}}
\@writefile{brf}{\backcite{foxBPHMM}{{6}{3.4.1}{subsubsection.3.4.1}}}
\@writefile{brf}{\backcite{ibp}{{6}{3.4.1}{equation.3.4}}}
\@writefile{brf}{\backcite{ibp}{{6}{3.4.1}{equation.3.4}}}
\@writefile{brf}{\backcite{foxBPHMM}{{6}{3.4.1}{equation.3.4}}}
\citation{foxBPHMM}
\citation{wikiHow}
\citation{wikiHow}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Graphical model for BP-HMM:} The left plate represent the set of activities and right plate represent the set of videos. Each video choose a subset of activities through $\mathbf  {f^{(i)}}$ and transition probabilities between them. After the features are selected, the marginal model of the each video becomes an Hidden Markov Model. \emph  {See the text for the details.}\relax }}{7}{figure.caption.13}}
\newlabel{bphmmo}{{6}{7}{\textbf {Graphical model for BP-HMM:} The left plate represent the set of activities and right plate represent the set of videos. Each video choose a subset of activities through $\mathbf {f^{(i)}}$ and transition probabilities between them. After the features are selected, the marginal model of the each video becomes an Hidden Markov Model. \emph {See the text for the details.}\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Gibbs sampling for BP-HMM}{7}{subsubsection.3.4.2}}
\@writefile{brf}{\backcite{foxBPHMM}{{7}{3.4.2}{subsubsection.3.4.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Experiments}{7}{section.4}}
\@writefile{brf}{\backcite{wikiHow}{{7}{4}{section.4}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Dataset}{7}{subsection.4.1}}
\newlabel{dataset:sec}{{4.1}{7}{\hskip -1em.~Dataset}{subsection.4.1}{}}
\@writefile{brf}{\backcite{wikiHow}{{7}{4.1}{subsection.4.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Implementation Details}{7}{subsection.4.2}}
\newlabel{imp_det}{{4.2}{7}{\hskip -1em.~Implementation Details}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Aligning Clusters:}{7}{section*.14}}
\citation{languageModel}
\citation{rabiner}
\citation{acticityFeature}
\citation{potapov2014category}
\citation{potapov2014category}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\hskip -1em.\nobreakspace  {}Qualitative Results}{8}{subsection.4.3}}
\@writefile{brf}{\backcite{languageModel}{{8}{4.3}{subsection.4.3}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}\hskip -1em.\nobreakspace  {}Quantitative Results}{8}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Baselines}{8}{subsubsection.4.4.1}}
\@writefile{brf}{\backcite{rabiner}{{8}{4.4.1}{subsubsection.4.4.1}}}
\@writefile{brf}{\backcite{acticityFeature}{{8}{4.4.1}{subsubsection.4.4.1}}}
\@writefile{brf}{\backcite{potapov2014category}{{8}{4.4.1}{subsubsection.4.4.1}}}
\@writefile{brf}{\backcite{potapov2014category}{{8}{4.4.1}{subsubsection.4.4.1}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Metrics}{8}{subsubsection.4.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Results}{8}{subsubsection.4.4.3}}
\@writefile{toc}{\contentsline {paragraph}{Are the activities detected accurately?}{8}{section*.17}}
\citation{potapov2014category}
\citation{potapov2014category}
\newlabel{recipe:ommelette}{{7a}{9}{How to make an omelet?\relax }{figure.caption.15}{}}
\newlabel{sub@recipe:ommelette}{{a}{9}{How to make an omelet?\relax }{figure.caption.15}{}}
\newlabel{recipe:milkshake}{{7b}{9}{How to make a milkshake?\relax }{figure.caption.15}{}}
\newlabel{sub@recipe:milkshake}{{b}{9}{How to make a milkshake?\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Temporal segmentation of the videos by our method and ground truth segmentation. We also color code the learned activity labels and visualize sample frames and the automatically generated captions for some of them. \emph  {Best viewed in color.}\relax }}{9}{figure.caption.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces $IOU_{max}$ values for all recipes, for all competing algorithms.\relax }}{9}{figure.caption.16}}
\newlabel{mIOU}{{8}{9}{$IOU_{max}$ values for all recipes, for all competing algorithms.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces $AP_{max}$ values for all recipes, for all competing algorithms.\relax }}{9}{figure.caption.16}}
\newlabel{mmAP}{{9}{9}{$AP_{max}$ values for all recipes, for all competing algorithms.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {paragraph}{Are the same activities in different videos linked to each other?}{9}{section*.19}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Average of $IOU_{max}$ and $mAP_{max}$ over recipes.\relax }}{9}{table.caption.18}}
\@writefile{brf}{\backcite{potapov2014category}{{9}{1}{table.caption.18}}}
\@writefile{brf}{\backcite{potapov2014category}{{9}{1}{table.caption.18}}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Semantic mean-average-precision $mAP_{sem}$ computed based on subjective evaluation.\relax }}{10}{table.caption.20}}
\@writefile{toc}{\contentsline {paragraph}{How important is each modality?}{10}{section*.21}}
\bibstyle{ieee}
\bibdata{recipeUnderstanding}
\bibcite{wikiHow}{1}
\bibcite{barbu2012video}{2}
\bibcite{matching}{3}
\bibcite{beetz}{4}
\bibcite{bojanowski14_eccv}{5}
\bibcite{cookie}{6}
\bibcite{cpmc}{7}
\bibcite{das2013thousand}{8}
\bibcite{duchenne09_iccv}{9}
\bibcite{efros03_iccv}{10}
\bibcite{farhadi2010every}{11}
\bibcite{fidler2013sentence}{12}
\bibcite{foxBPHMM}{13}
\bibcite{photoshop}{14}
\bibcite{ibp}{15}
\bibcite{gupta2009understanding}{16}
\bibcite{createSum}{17}
\bibcite{hoai11_cvpr}{18}
\bibcite{beyondSearch}{19}
\bibcite{jain13_cvpr}{20}
\bibcite{jainuniversity}{21}
\bibcite{THUMOS14}{22}
\bibcite{deepAlignment}{23}
\bibcite{khosla2013large}{24}
\bibcite{kim2014joint}{25}
\bibcite{storyGraph}{26}
\bibcite{kiros2014multimodal}{27}
\bibcite{kong2014you}{28}
\bibcite{kuehne2011hmdb}{29}
\bibcite{lan14_vs}{30}
\bibcite{lan14_eccv}{31}
\bibcite{laptev08_cvpr}{32}
\bibcite{laptev07_iccv}{33}
\bibcite{lee2012discovering}{34}
\bibcite{keysegments}{35}
\bibcite{lu2013story}{36}
\bibcite{alignment}{37}
\bibcite{cookingSemantics}{38}
\bibcite{flowGraph}{39}
\bibcite{motwani2012improving}{40}
\bibcite{niebles10_eccv}{41}
\bibcite{scgp}{42}
\bibcite{oneata2014lear}{43}
\bibcite{ordonez2011im2text}{44}
\bibcite{scgp_eigen}{45}
\bibcite{pirsiavash14_cvpr}{46}
\bibcite{potapov2014category}{47}
\bibcite{rabiner}{48}
\bibcite{rui2000automatically}{49}
\bibcite{ryoo09_iccv}{50}
\bibcite{connecting}{51}
\bibcite{socher2014grounded}{52}
\bibcite{UCF101}{53}
\bibcite{sun2014discover}{54}
\bibcite{logicRecipe}{55}
\bibcite{vidAbstraction}{56}
\bibcite{yao10b_cvpr}{57}
\bibcite{yu2013grounded}{58}
\bibcite{zitnick2013bringing}{59}
\bibcite{zitnick2013learning}{60}
